import os
import asyncio
import json
import random
import logging
import re
import subprocess
import shutil
import numpy as np
from aiogram import types, Bot
from aiogram.types import FSInputFile
from PIL import Image
import multiprocessing
import tempfile
from concurrent.futures import ThreadPoolExecutor

# –ü–æ–ø—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å seam_carving
try:
    import seam_carving
    SEAM_CARVING_AVAILABLE = True
except ImportError:
    logging.warning("–ú–æ–¥—É–ª—å 'seam_carving' –Ω–µ –Ω–∞–π–¥–µ–Ω. –§—É–Ω–∫—Ü–∏–∏ seam carving –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")
    SEAM_CARVING_AVAILABLE = False

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –≤–∞—à–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
from config import bot as main_bot_instance
from whatisthere import download_file

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø –†–ï–°–£–†–°–û–í ---
MAX_AUDIO_DURATION = 180  # 3 –º–∏–Ω—É—Ç—ã
MAX_VIDEO_DURATION = 60   # 1 –º–∏–Ω—É—Ç–∞ –¥–ª—è –≤–∏–¥–µ–æ
MAX_FILE_SIZE = 20_000_000  # 20MB

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---

def map_intensity(intensity: int, out_min: float, out_max: float) -> float:
    return out_min + (intensity / 100.0) * (out_max - out_min)

def parse_intensity_from_text(text: str | None) -> int:
    if not text: return 45
    match = re.search(r'\b(\d+)\b', text)
    if match: return max(0, min(100, [jg:–ø–∞—Ä–æ–ª—å_(regexp)_190]1))))
    return 45

async def run_ffmpeg_command(command: list[str]) -> tuple[bool, str]:
    logging.info(f"–ó–∞–ø—É—Å–∫ FFmpeg: {' '.join(command)}")
    process = await asyncio.create_subprocess_exec(
        *command, stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )
    _, stderr = await process.communicate()
    if process.returncode != 0:
        error_message = stderr.decode(errors='ignore').strip()
        logging.error(f"FFmpeg –æ—à–∏–±–∫–∞: {error_message}")
        return False, error_message
    return True, "Success"

async def get_media_info(file_path: str) -> dict | None:
    command = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_streams', '-show_format', '-i', file_path]
    process = await asyncio.create_subprocess_exec(*command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, _ = await process.communicate()
    if process.returncode != 0: return None
    try: return json.loads(stdout.decode(errors='ignore'))
    except json.JSONDecodeError: return None

async def get_video_frame_rate(file_path: str) -> tuple[str, float]:
    """–ü–æ–ª—É—á–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—É –∫–∞–¥—Ä–æ–≤ –∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ"""
    info = await get_media_info(file_path)
    if not info:
        return "30/1", 0.0
    
    duration = 0.0
    frame_rate = "30/1"
    
    if 'format' in info and 'duration' in info['format']:
        duration = float(info['format']['duration'])
    
    for stream in info.get('streams', []):
        if stream.get('codec_type') == 'video':
            if 'avg_frame_rate' in stream and stream['avg_frame_rate'] != '0/0':
                frame_rate = stream['avg_frame_rate']
            elif 'r_frame_rate' in stream and stream['r_frame_rate'] != '0/0':
                frame_rate = stream['r_frame_rate']
            break
    
    return frame_rate, duration

# --- –§—É–Ω–∫—Ü–∏–∏ –∏—Å–∫–∞–∂–µ–Ω–∏—è ---

def distort_text(text: str, intensity: int) -> str:
    chars = list(text)
    num_changes = int(len(chars) * (intensity / 100.0))
    for _ in range(num_changes):
        idx = random.randint(0, len(chars) - 1)
        if chars[idx].isspace(): continue
        action = random.randint(0, 2)
        if action == 0: chars[idx] = chars[idx].swapcase()
        elif action == 1: chars[idx] += random.choice([chr(c) for c in range(0x0300, [jg:–ø–∞—Ä–æ–ª—å_(regexp)_191]
        else: chars.insert(idx, random.choice("!@#$%^&*()_+-=[]{}|;:,.<>?"))
    return "".join(chars)

async def apply_ffmpeg_audio_distortion(input_path: str, output_path: str, intensity: int) -> bool:
    """–ò—Å–∫–∞–∂–∞–µ—Ç –∞—É–¥–∏–æ, –∏—Å–ø–æ–ª—å–∑—É—è vibrato –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç."""
    vibrato_freq = map_intensity(intensity, 4.0, 12.0)
    vibrato_depth = map_intensity(intensity, 0.2, 2.0)
    
    filters = [jg:–ø–∞—Ä–æ–ª—å_(regexp)_192]brato_freq:.2f}:[jg:–ø–∞—Ä–æ–ª—å_(regexp)_193]:.2f}"]
    
    if intensity > 50:
        crush = map_intensity(intensity, 0.2, 1.0)
        [jg:–ø–∞—Ä–æ–ª—å_(regexp)_194]"acrusher=bits=8:mode=log:mix={crush}")
        
    if intensity > 75:
        decay = map_intensity(intensity, 0.1, 0.4)
        delay = map_intensity(intensity, 20, 200)
        [jg:–ø–∞—Ä–æ–ª—å_(regexp)_195]"aecho=0.8:0.9:{delay}:{decay}")

    cmd = ['ffmpeg', '-i', input_path, '-af', ",".join(filters), '-c:a', 'libmp3lame', '-q:a', '4', '-y', output_path]
    success, _ = await run_ffmpeg_command(cmd)
    return success

def _seam_carving_blocking_task(src_np, original_w, original_h, new_w, new_h, out_path):
    dst = seam_carving.resize(src_np, (new_w, new_h), energy_mode='backward', order='width-first')
    Image.fromarray(dst).resize((original_w, original_h), Image.LANCZOS).save(out_path, "JPEG", [jg:–ø–∞—Ä–æ–ª—å_(regexp)_196]

async def apply_seam_carving_distortion(input_path: str, output_path: str, intensity: int) -> bool:
    if not SEAM_CARVING_AVAILABLE: return False
    try:
        distort_percent = max(0, min(intensity, 95))
        with Image.open(input_path) as img:
            if img.width < 50 or img.height < 50: return False
            original_width, original_height = img.size
            src = np.array(img.convert("RGB"))
        new_width = max(int(original_width * (100 - distort_percent) / 100), 20)
        new_height = max(int(original_height * (100 - distort_percent) / 100), 20)
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, _seam_carving_blocking_task, src, original_width, original_height, new_width, new_height, output_path)
        return True
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ seam carving: {e}", exc_info=True)
        return False

def distort_image_sync(image_path: str) -> bool:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–∫–∞–∂–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ –∫–∞–¥—Ä–∞"""
    try:
        with Image.open(image_path) as img:
            # –ü—Ä–æ—Å—Ç–æ–µ –∏—Å–∫–∞–∂–µ–Ω–∏–µ –±–µ–∑ seam carving –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            width, height = img.size
            
            # –°–ª—É—á–∞–π–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏ –≤–æ–∑–≤—Ä–∞—Ç –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—É
            scale_factor = random.uniform(0.7, 0.9)
            new_width = int(width * scale_factor)
            new_height = int(height * scale_factor)
            
            # –ò—Å–∫–∞–∂–∞–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É
            distorted = img.resize((new_width, new_height), Image.LANCZOS)
            distorted = distorted.resize((width, height), Image.NEAREST)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ü–≤–µ—Ç–æ–≤—ã–µ –∏—Å–∫–∞–∂–µ–Ω–∏—è
            pixels = np.array(distorted)
            noise = [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_197](-20, 20, pixels.shape, [jg:–ø–∞—Ä–æ–ª—å_(regexp)_198]
            pixels = np.clip(pixels.astype(np.int16) + noise, 0, [jg:–ø–∞—Ä–æ–ª—å_(regexp)_199]int8)
            
            distorted = Image.fromarray(pixels)
            distorted.save(image_path, "PNG")
            return True
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∏—Å–∫–∞–∂–µ–Ω–∏—è –∫–∞–¥—Ä–∞ {image_path}: {e}")
        return False

async def extract_frames_from_video(input_path: str, frames_dir: str, frame_rate: str) -> bool:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–¥—Ä—ã –∏–∑ –≤–∏–¥–µ–æ"""
    frame_pattern = [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_200](frames_dir, [jg:–ø–∞—Ä–æ–ª—å_(regexp)_201])
    cmd = ['ffmpeg', '-i', input_path, '-r', frame_rate, frame_pattern, '-y']
    success, _ = await run_ffmpeg_command(cmd)
    return success

async def distort_frames_parallel(frames_dir: str, progress_callback=None) -> bool:
    """–ò—Å–∫–∞–∂–∞–µ—Ç –∫–∞–¥—Ä—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ"""
    try:
        frame_files = [f for f in os.listdir(frames_dir) if f.endswith('.png')]
        frame_files.sort()
        
        if not frame_files:
            return False
        
        total_frames = len(frame_files)
        processed = 0
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º ThreadPoolExecutor –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        with ThreadPoolExecutor(max_workers=min(4, multiprocessing.cpu_count())) as executor:
            loop = asyncio.get_running_loop()
            
            for frame_file in frame_files:
                frame_path = [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_202](frames_dir, frame_file)
                await loop.run_in_executor(executor, distort_image_sync, frame_path)
                processed += 1
                
                if progress_callback and processed % 10 == 0:  # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 –∫–∞–¥—Ä–æ–≤
                    await progress_callback(processed, total_frames)
        
        return True
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∏—Å–∫–∞–∂–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤: {e}")
        return False

async def collect_frames_to_video(frames_dir: str, output_path: str, frame_rate: str, media_type: str) -> bool:
    """–°–æ–±–∏—Ä–∞–µ—Ç –∫–∞–¥—Ä—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ –≤–∏–¥–µ–æ"""
    frame_pattern = [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_203](frames_dir, [jg:–ø–∞—Ä–æ–ª—å_(regexp)_204])
    
    if media_type == 'animation':  # GIF
        cmd = ['ffmpeg', '-r', frame_rate, '-i', frame_pattern, '-f', 'mp4', 
               '-c:v', 'libx264', '-pix_fmt', 'yuv420p', '-an', output_path, '-y']
    elif media_type == 'video_note':  # –ö—Ä—É–∂–æ—á–∫–∏
        cmd = ['ffmpeg', '-r', frame_rate, '-i', frame_pattern, '-f', 'mp4',
               '-c:v', 'libx264', '-pix_fmt', 'yuv420p', '-an', output_path, '-y']
    elif media_type == 'sticker_video':  # –í–∏–¥–µ–æ—Å—Ç–∏–∫–µ—Ä—ã
        cmd = ['ffmpeg', '-r', frame_rate, '-i', frame_pattern, '-f', 'webm',
               '-c:v', 'libvpx-vp9', '-b:v', '85k', '-pix_fmt', 'yuva420p', '-an', output_path, '-y']
    else:  # –û–±—ã—á–Ω–æ–µ –≤–∏–¥–µ–æ
        cmd = ['ffmpeg', '-r', frame_rate, '-i', frame_pattern, '-f', 'mp4',
               '-c:v', 'libx264', '-pix_fmt', 'yuv420p', '-an', output_path, '-y']
    
    success, _ = await run_ffmpeg_command(cmd)
    return success

async def distort_video_with_audio(input_path: str, output_path: str, intensity: int, media_type: str, progress_callback=None) -> bool:
    """–ò—Å–∫–∞–∂–∞–µ—Ç –≤–∏–¥–µ–æ —Å –∞—É–¥–∏–æ (–µ—Å–ª–∏ –µ—Å—Ç—å)"""
    try:
        temp_dir = tempfile.mkdtemp()
        frames_dir = [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_205](temp_dir, "frames")
        os.makedirs(frames_dir, exist_ok=True)
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ
        frame_rate, duration = await get_video_frame_rate(input_path)
        
        if progress_callback:
            await progress_callback("–ò–∑–≤–ª–µ–∫–∞—é –∫–∞–¥—Ä—ã...")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã
        if not await extract_frames_from_video(input_path, frames_dir, frame_rate):
            return False
        
        if progress_callback:
            await progress_callback("–ò—Å–∫–∞–∂–∞—é –∫–∞–¥—Ä—ã...")
        
        # –ò—Å–∫–∞–∂–∞–µ–º –∫–∞–¥—Ä—ã
        async def frame_progress(processed, total):
            if progress_callback:
                progress = int((processed / total) * 70) + 20  # 20-90% –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                await progress_callback(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {processed}/{total} ({progress}%)")
        
        if not await distort_frames_parallel(frames_dir, frame_progress):
            return False
        
        if progress_callback:
            await progress_callback("–°–æ–±–∏—Ä–∞—é –≤–∏–¥–µ–æ...")
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –≤–∏–¥–µ–æ –±–µ–∑ –∑–≤—É–∫–∞
        temp_video = [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_206](temp_dir, [jg:–ø–∞—Ä–æ–ª—å_(regexp)_207])
        if not await collect_frames_to_video(frames_dir, temp_video, frame_rate, media_type):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∞—É–¥–∏–æ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
        info = await get_media_info(input_path)
        has_audio = False
        if info:
            for stream in info.get('streams', []):
                if stream.get('codec_type') == 'audio':
                    has_audio = True
                    break
        
        if has_audio and media_type not in ['sticker_video', 'video_note']:
            # –ò—Å–∫–∞–∂–∞–µ–º –∞—É–¥–∏–æ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º
            temp_audio = [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_208](temp_dir, [jg:–ø–∞—Ä–æ–ª—å_(regexp)_209])
            if await apply_ffmpeg_audio_distortion(input_path, temp_audio, intensity):
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ
                cmd = ['ffmpeg', '-i', temp_video, '-i', temp_audio, 
                       '-c:v', 'copy', '-c:a', 'copy', output_path, '-y']
                success, _ = await run_ffmpeg_command(cmd)
            else:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞—É–¥–∏–æ, –∫–æ–ø–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ
                cmd = ['ffmpeg', '-i', temp_video, '-i', input_path, 
                       '-c:v', 'copy', '-c:a', 'copy', '-map', '0:v:0', '-map', '1:a:0', 
                       output_path, '-y']
                success, _ = await run_ffmpeg_command(cmd)
        else:
            # –ü—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º –≤–∏–¥–µ–æ –±–µ–∑ –∑–≤—É–∫–∞
            shutil.copy2(temp_video, output_path)
            success = True
        
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        shutil.rmtree(temp_dir, ignore_errors=True)
        return success
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∏—Å–∫–∞–∂–µ–Ω–∏—è –≤–∏–¥–µ–æ: {e}")
        return False

# --- –ò–ó–û–õ–ò–†–û–í–ê–ù–ù–´–ô –ü–†–û–¶–ï–°–° –û–ë–†–ê–ë–û–¢–ö–ò ---

async def distortion_worker_async(bot_token: str, chat_id: int, media_info: dict, intensity: int):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —á–∞—Å—Ç—å –≤–æ—Ä–∫–µ—Ä–∞, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç –≤—Å—é —Ä–∞–±–æ—Ç—É."""
    bot_instance = Bot(token=bot_token)
    progress_message = None
    
    media_type = media_info['media_type']
    input_path = media_info.get('local_path')
    output_path = None
    
    async def update_progress(text):
        nonlocal progress_message
        try:
            if progress_message is None:
                progress_message = await bot_instance.send_message(chat_id, f"üåÄ {text}")
            else:
                # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ edit_message_text
                await bot_instance.edit_message_text(
                    text=f"üåÄ {text}",
                    chat_id=chat_id,
                    message_id=progress_message.message_id
                )
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ
        if media_type in ['audio', 'voice', 'video', 'animation', 'video_note', 'sticker_video']:
            info = await get_media_info(input_path)
            if not info or 'format' not in info:
                await bot_instance.send_message(chat_id, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ.")
                return

            duration = float(info['format'].get('duration', 0))
            
            if media_type in ['audio', 'voice'] and duration > MAX_AUDIO_DURATION:
                await bot_instance.send_message(chat_id, f"–°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª ({duration:.1f}—Å > {MAX_AUDIO_DURATION}—Å).")
                return
            elif media_type in ['video', 'animation', 'video_note', 'sticker_video'] and duration > MAX_VIDEO_DURATION:
                await bot_instance.send_message(chat_id, f"–°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ –≤–∏–¥–µ–æ ({duration:.1f}—Å > {MAX_VIDEO_DURATION}—Å).")
                return

        success, final_media_type = False, None
        
        if media_type == 'text':
            distorted_text = distort_text(media_info['text'], intensity)
            await bot_instance.send_message(chat_id, distorted_text)
            return

        elif media_type in ['photo', 'sticker_static']:
            output_path = f"{input_path}_out.jpg"
            success = await apply_seam_carving_distortion(input_path, output_path, intensity)
            final_media_type = 'photo'

        elif media_type in ['audio', 'voice']:
            output_path = [jg:–ø–∞—Ä–æ–ª—å_(regexp)_210]ut.mp3"
            success = await apply_ffmpeg_audio_distortion(input_path, output_path, intensity)
            final_media_type = media_type

        elif media_type in ['video', 'animation', 'video_note', 'sticker_video']:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            if media_type == 'sticker_video':
                output_path = f"{input_path}_out.webm"
            else:
                output_path = [jg:–ø–∞—Ä–æ–ª—å_(regexp)_211]ut.mp4"
            
            success = await distort_video_with_audio(input_path, output_path, intensity, media_type, update_progress)
            final_media_type = media_type

        if success and output_path and [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_212](output_path):
            file_to_send = FSInputFile(output_path)
            
            try:
                if progress_message:
                    await bot_instance.delete_message(chat_id, progress_message.message_id)
            except:
                pass
            
            if final_media_type == 'photo': 
                await bot_instance.send_photo(chat_id, file_to_send, caption="üåÄ —Ç–≤–æ—è —Ö—É–π–Ω—è –≥–æ—Ç–æ–≤–∞")
            elif final_media_type == 'audio': 
                await bot_instance.send_audio(chat_id, file_to_send, caption="üåÄ —Ç–≤–æ—è —Ö—É–π–Ω—è –≥–æ—Ç–æ–≤–∞")
            elif final_media_type == 'voice': 
                await bot_instance.send_voice(chat_id, file_to_send, caption="üåÄ —Ç–≤–æ—è —Ö—É–π–Ω—è –≥–æ—Ç–æ–≤–∞")
            elif final_media_type == 'video':
                await bot_instance.send_video(chat_id, file_to_send, caption="üåÄ —Ç–≤–æ—è —Ö—É–π–Ω—è –≥–æ—Ç–æ–≤–∞")
            elif final_media_type == 'animation':
                await bot_instance.send_animation(chat_id, file_to_send, caption="üåÄ —Ç–≤–æ—è —Ö—É–π–Ω—è –≥–æ—Ç–æ–≤–∞")
            elif final_media_type == 'video_note':
                await bot_instance.send_video_note(chat_id, file_to_send)
            elif final_media_type == 'sticker_video':
                await bot_instance.send_document(chat_id, file_to_send, caption="üåÄ —Ç–≤–æ—è —Ö—É–π–Ω—è –≥–æ—Ç–æ–≤–∞")
        else:
            await bot_instance.send_message(chat_id, "–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ –≤–æ –≤—Ä–µ–º—è –∏—Å–∫–∞–∂–µ–Ω–∏—è.")

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤ –≤–æ—Ä–∫–µ—Ä–µ: {e}", exc_info=True)
        try: 
            await bot_instance.send_message(chat_id, "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ.")
        except Exception as send_e: 
            logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ: {send_e}")
    finally:
        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if input_path and [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_213](input_path).startswith("temp_worker_"):
            shutil.rmtree([jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_214](input_path), ignore_errors=True)
        if output_path and [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_215](output_path):
            try:
                os.remove(output_path)
            except:
                pass
        await [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_216]()

def distortion_worker_proc(bot_token: str, chat_id: int, media_info: dict, intensity: int):
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞. –ó–∞–ø—É—Å–∫–∞–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤–æ—Ä–∫–µ—Ä."""
    logging.info(f"–ó–∞–ø—É—â–µ–Ω –Ω–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è –∏—Å–∫–∞–∂–µ–Ω–∏—è (PID: {os.getpid()})")
    asyncio.run(distortion_worker_async(bot_token, chat_id, media_info, intensity))

# --- –§–∏–ª—å—Ç—Ä –∏ –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ ---

def is_distortion_command(message: types.Message) -> bool:
    try:
        from config import BLOCKED_USERS
        if [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_217] in BLOCKED_USERS: return False
        text_to_check = message.caption or message.text
        if text_to_check and "–¥–∏—Å—Ç–æ—Ä—à–Ω" in text_to_check.lower():
            target = message.reply_to_message or message
            return bool(target.photo or target.sticker or target.audio or target.voice or 
                       target.text or target.video or target.animation or target.video_note)
        return False
    except Exception: return False

async def handle_distortion_request(message: types.Message):
    """–û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫. –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –∏—Å–∫–∞–∂–µ–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ."""
    try:
        target_message = message.reply_to_message or message
        text_for_parsing = message.text if message.text else message.caption
        intensity = parse_intensity_from_text(text_for_parsing)
        
        media_info = {}
        file_to_download = None
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        file_size = 0
        if target_message.photo: 
            media_info = {'media_type': 'photo', 'ext': '.jpg'}
            file_to_download = [jg:–ø–∞—Ä–æ–ª—å_(regexp)_218]hoto[-1]
            file_size = file_to_download.file_size or 0
        elif target_message.sticker:
            # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∏–¥–µ–æ—Å—Ç–∏–∫–µ—Ä–æ–≤
            if target_message.sticker.is_video:
                media_info = {'media_type': 'sticker_video', 'ext': '.webm'}
                file_to_download = target_message.sticker
                file_size = file_to_download.file_size or 0
            elif target_message.sticker.is_animated:
                await message.answer("–ò–∑–≤–∏–Ω–∏, –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∏–∫–µ—Ä—ã (TGS) –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è.")
                return
            else: 
                media_info = {'media_type': 'sticker_static', 'ext': '.webp'}
                file_to_download = target_message.sticker
                file_size = file_to_download.file_size or 0
        elif target_message.audio: 
            media_info = {'media_type': 'audio', 'ext': '.mp3'}
            file_to_download = target_message.audio
            file_size = file_to_download.file_size or 0
        elif target_message.voice: 
            media_info = {'media_type': 'voice', 'ext': '.ogg'}
            file_to_download = target_message.voice
            file_size = file_to_download.file_size or 0
        elif target_message.video:
            media_info = {'media_type': 'video', 'ext': '.mp4'}
            file_to_download = target_message.video
            file_size = file_to_download.file_size or 0
        elif target_message.animation:
            media_info = {'media_type': 'animation', 'ext': '.mp4'}
            file_to_download = target_message.animation
            file_size = file_to_download.file_size or 0
        elif target_message.video_note:
            media_info = {'media_type': 'video_note', 'ext': '.mp4'}
            file_to_download = target_message.video_note
            file_size = file_to_download.file_size or 0
        elif target_message.text: 
            media_info = {'media_type': 'text', 'text': target_message.text}

        if not media_info:
            await message.answer("–ù–µ –Ω–∞—à–µ–ª, —á—Ç–æ –∏—Å–∫–∞–∂–∞—Ç—å.")
            return

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        if file_size > MAX_FILE_SIZE:
            await message.answer(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({file_size/1024/1024:.1f}MB > [jg:–ø–∞—Ä–æ–ª—å_(regexp)_219]024/1024:.1f}MB)")
            return

        if file_to_download:
            temp_dir = f"temp_worker_{random.randint(1000, 9999)}"
            os.makedirs(temp_dir, exist_ok=True)
            local_path = [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_220](temp_dir, f"input{media_info['ext']}")
            
            if not await download_file(file_to_download.file_id, local_path):
                await message.answer("–ù–µ —Å–º–æ–≥ —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª.")
                shutil.rmtree(temp_dir, ignore_errors=True)
                return
            media_info['local_path'] = local_path

        await message.answer("üåÄ —â–∞, —Å—É–∫–∞, –∏—Å–∫–∞–∂—É...")
        
        try:
            multiprocessing.set_start_method("spawn", force=True)
        except RuntimeError:
            pass
            
        proc = multiprocessing.Process(
            target=distortion_worker_proc, 
            args=(main_bot_instance.token, [jg:–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π_—Ç–æ–∫–µ–Ω_221], media_info, intensity)
        )
        proc.start()

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤ handle_distortion_request: {e}", exc_info=True)
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É.")