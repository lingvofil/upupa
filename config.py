import google.generativeai as genai
from google.api_core import exceptions
import logging
from aiogram import Bot, Dispatcher, Router
import requests
import json
from typing import List, Dict, Any, Optional, Union
from gigachat import GigaChat
import os

# === –ë–õ–û–ö –ò–ú–ü–û–†–¢–ê –ö–õ–Æ–ß–ï–ô ===
try:
    from config_private import (
        API_TOKEN,
        GENERIC_API_KEY3, GENERIC_API_KEY2, GENERIC_API_KEY4,
        GENERIC_API_KEY5, GENERIC_API_KEY6, GENERIC_API_KEY,
        OPENROUTER_API_KEY,
        GOOGLE_API_KEY, GOOGLE_API_KEY2,
        giphy_api_key,
        KANDINSKY_API_KEY, KANDINSKY_SECRET_KEY,
        GIGACHAT_API_KEY, GIGACHAT_CLIENT_ID
    )
except ImportError:
    print("Warning: config_private.py not found. Attempting to load from environment variables.")
    API_TOKEN = os.getenv('API_TOKEN', '')
    GENERIC_API_KEY = os.getenv('GENERIC_API_KEY', '')
    OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY', '')
    # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–≥–ª—É—à–∫–∏ ...

SEARCH_ENGINE_ID = "33026288e406447ea"
GIGACHAT_MODEL = 'GigaChat-2'
GIGACHAT_MODEL_PRO = 'GigaChat-2-Pro'
GIGACHAT_MODEL_MAX = 'GigaChat-2-Max'

# === –ù–ê–°–¢–†–û–ô–ö–ê GEMINI ===
genai.configure(api_key=GENERIC_API_KEY)

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π. –ë–æ—Ç –±—É–¥–µ—Ç –ø—Ä–æ–±–æ–≤–∞—Ç—å –∏—Ö –ø–æ –æ—á–µ—Ä–µ–¥–∏.
MODEL_QUEUE = [
    'gemini-2.5-flash-preview-09-2025',     # 10 RPM (–≤ –º–∏–Ω—É—Ç—É) / 250 RPD (–≤ –¥–µ–Ω—å)
    'gemini-2.5-pro',                        # 2 RPM (–≤ –º–∏–Ω—É—Ç—É) / 50 RPD (–≤ –¥–µ–Ω—å)
    'gemini-2.5-flash',                      # 10 RPM (–≤ –º–∏–Ω—É—Ç—É) / 250 RPD (–≤ –¥–µ–Ω—å)
    'gemini-2.0-flash',                      # 15 RPM (–≤ –º–∏–Ω—É—Ç—É) / 200 RPD (–≤ –¥–µ–Ω—å)
    'gemini-2.5-flash-lite-preview-09-2025',# 15 RPM (–≤ –º–∏–Ω—É—Ç—É) / 1000 RPD (–≤ –¥–µ–Ω—å)
    'gemini-2.5-flash-lite',                 # 15 RPM (–≤ –º–∏–Ω—É—Ç—É) / 1000 RPD (–≤ –¥–µ–Ω—å)
    'gemini-2.0-flash-lite',                 # 30 RPM (–≤ –º–∏–Ω—É—Ç—É) / 200 RPD (–≤ –¥–µ–Ω—å)
    'gemini-1.5-flash'                       # 15 RPM (–≤ –º–∏–Ω—É—Ç—É) / 50 RPD (–≤ –¥–µ–Ω—å)
]

class ModelFallbackWrapper:
    def __init__(self, model_names):
        self.model_names = model_names

    def generate_content(self, *args, **kwargs):
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç, –ø–µ—Ä–µ–±–∏—Ä–∞—è –º–æ–¥–µ–ª–∏ –∏–∑ —Å–ø–∏—Å–∫–∞.
        """
        last_error = None
        
        for model_name in self.model_names:
            try:
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å
                current_model = genai.GenerativeModel(model_name)
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç
                return current_model.generate_content(*args, **kwargs)
            
            except exceptions.ResourceExhausted:
                logging.warning(f"‚ö†Ô∏è –õ–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –∏—Å—á–µ—Ä–ø–∞–Ω –¥–ª—è {model_name}. –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å...")
                continue
            
            except Exception as e:
                # –õ–æ–≤–∏–º –æ—à–∏–±–∫–∏ 404 (–º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞) –∏–ª–∏ 503 (—Å–µ—Ä–≤–µ—Ä –∑–∞–Ω—è—Ç)
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
                last_error = e
                continue
        
        # –ï—Å–ª–∏ —Ü–∏–∫–ª –∑–∞–∫–æ–Ω—á–∏–ª—Å—è, –∞ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç
        logging.error("üî• –í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã!")
        raise last_error if last_error else Exception("–í—Å–µ –º–æ–¥–µ–ª–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã.")

    def start_chat(self, history=None):
        """
        –ú–µ—Ç–æ–¥-–∑–∞–≥–ª—É—à–∫–∞ –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –∫–∞–∫–æ–π-—Ç–æ –º–æ–¥—É–ª—å –≤—ã–∑–æ–≤–µ—Ç start_chat.
        –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å.
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å —Å –∫–æ–Ω—Ü–∞ —Å–ø–∏—Å–∫–∞ (–æ–±—ã—á–Ω–æ 1.5-flash), —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –¥–ª—è —á–∞—Ç–∞
        safe_model = self.model_names[-1] 
        return genai.GenerativeModel(safe_model).start_chat(history=history)

# –°–æ–∑–¥–∞–µ–º "—É–º–Ω—É—é" –º–æ–¥–µ–ª—å
model = ModelFallbackWrapper(MODEL_QUEUE)

# –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
advanced_model = genai.GenerativeModel('gemini-2.0-flash') 
image_model = genai.GenerativeModel("models/gemini-2.0-flash")
edit_model = genai.GenerativeModel("models/gemini-2.0-flash-preview-image-generation")


# === OPENROUTER ===
class OpenRouterModel:
    def __init__(self, model_name: str):
        self.model_name = model_name
        self.api_key = OPENROUTER_API_KEY
        self.url = "https://openrouter.ai/api/v1/chat/completions"
        
    def generate_content(self, prompt: Union[str, List[Dict[str, Any]]], 
                         temperature: float = 0.7, max_tokens: int = 1024,
                         site_url: str = None, site_name: str = None) -> 'OpenRouterResponse':
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        if site_url: headers["HTTP-Referer"] = site_url
        if site_name: headers["X-Title"] = site_name
        
        content_list = [{"type": "text", "text": prompt}] if isinstance(prompt, str) else prompt
        
        data = {
            "model": self.model_name,
            "messages": [{"role": "user", "content": content_list}],
            "temperature": temperature,
            "max_tokens": max_tokens
        }
        
        response = requests.post(self.url, headers=headers, data=json.dumps(data))
        if response.status_code != 200:
            raise Exception(f"–û—à–∏–±–∫–∞ API OpenRouter: {response.text}")
        
        return OpenRouterResponse(response.json())
    
    def create_multimodal_content(self, text: str, image_urls: List[str]):
        content = [{"type": "text", "text": text}]
        for url in image_urls:
            content.append({"type": "image_url", "image_url": {"url": url}})
        return content

class OpenRouterResponse:
    def __init__(self, response_data: Dict[str, Any]):
        self.response_data = response_data
        self.text = self._extract_text()
        
    def _extract_text(self) -> str:
        choices = self.response_data.get("choices", [])
        return choices[0].get("message", {}).get("content", "") if choices else ""

model2 = OpenRouterModel('openai/gpt-3.5-turbo')
advanced_model2 = OpenRouterModel('anthropic/claude-3-haiku')


# === –ù–ê–°–¢–†–û–ô–ö–ò –ò –ü–ï–†–ï–ú–ï–ù–ù–´–ï ===
BLOCKED_USERS = [354145389]
ADMIN_ID = 126386976
SPECIAL_CHAT_ID = -1001707530786

CHAT_SETTINGS_FILE = "chat_settings.json"
LOG_FILE = "user_messages.log"
STATS_FILE = "message_stats.json"
CHAT_LIST_FILE = "chats.json"
SMS_DISABLED_CHATS_FILE = "sms_disabled_chats.json"
DB_FILE = "statistics.db" 

# === –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï –°–û–°–¢–û–Ø–ù–ò–Ø ===
# (–û—á–µ–Ω—å –≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã –æ–Ω–∏ –±—ã–ª–∏ –∑–¥–µ—Å—å, –∏–Ω–∞—á–µ –≤–∏–∫—Ç–æ—Ä–∏–Ω–∞ –Ω–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å)
chat_settings = {}
conversation_history = {}
message_stats = {}

# –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –≤–∏–∫—Ç–æ—Ä–∏–Ω
quiz_questions = {} 
quiz_states = {} 

chat_list = []
sms_disabled_chats = set()
ANTISPAM_ENABLED_CHATS = set()

DAILY_PROMPT = None
LAST_PROMPT_UPDATE = None
DIALOG_ENABLED = True
MAX_HISTORY_LENGTH = 20

# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ===
bot = Bot(token=API_TOKEN)
dp = Dispatcher()
router = Router()

logging.basicConfig(
    level=logging.INFO,
    filename="bot_log.txt",
    filemode="a",
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)
