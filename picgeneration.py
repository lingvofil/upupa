import requests
import json
import time
import aiohttp
import asyncio
import tempfile
import os
import logging
import random
import textwrap
import base64
import google.generativeai as genai
from io import BytesIO
from PIL import Image, ImageDraw, ImageFont
from aiogram import types
from aiogram.types import FSInputFile

# Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð²ÑÐµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹
from config import KANDINSKY_API_KEY, KANDINSKY_SECRET_KEY, bot, model, image_model, API_TOKEN
from prompts import actions
from adddescribe import download_telegram_image
from gemini_generation import process_gemini_generation, save_and_send_generated_image as save_and_send_gemini

# =============================================================================
# ÐšÐ»Ð°ÑÑ Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ API Kandinsky (FusionBrain)
# =============================================================================

class FusionBrainAPI:
    def __init__(self, url, api_key, secret_key):
        self.URL = url
        self.AUTH_HEADERS = {
            'X-Key': f'Key {api_key}',
            'X-Secret': f'Secret {secret_key}',
        }

    def get_pipeline(self):
        try:
            response = requests.get(self.URL + 'key/api/v1/pipelines', headers=self.AUTH_HEADERS)
            response.raise_for_status()
            data = response.json()
            if data and 'id' in data[0]:
                return data[0]['id']
            else:
                logging.error("API Ð½Ðµ Ð²ÐµÑ€Ð½ÑƒÐ» Ð¾Ð¶Ð¸Ð´Ð°ÐµÐ¼ÑƒÑŽ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ Ð´Ð»Ñ pipeline.")
                return None
        except requests.RequestException as e:
            logging.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ pipeline: {e}")
            return None

    def generate(self, prompt, pipeline, images=1, width=1024, height=1024):
        params = {
            "type": "GENERATE",
            "numImages": images,
            "width": width,
            "height": height,
            "generateParams": {
                "query": f'{prompt}'
            }
        }
        data = {
            'pipeline_id': (None, pipeline),
            'params': (None, json.dumps(params), 'application/json')
        }
        try:
            response = requests.post(self.URL + 'key/api/v1/pipeline/run', headers=self.AUTH_HEADERS, files=data)
            response.raise_for_status()
            data = response.json()
            if 'uuid' in data:
                return data['uuid'], None
            error_message = data.get('errorDescription') or data.get('message') or data.get('pipeline_status') or json.dumps(data)
            logging.error(f"Kandinsky API Ð½Ðµ Ð²ÐµÑ€Ð½ÑƒÐ» UUID. ÐžÑ‚Ð²ÐµÑ‚: {error_message}")
            return None, error_message
        except requests.RequestException as e:
            logging.error(f"HTTP Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐµ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸: {e}")
            return None, str(e)
        except json.JSONDecodeError:
            logging.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ JSON Ð¾Ñ‚Ð²ÐµÑ‚Ð°: {response.text}")
            return None, "API Ð²ÐµÑ€Ð½ÑƒÐ» Ð½ÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ JSON."

    def check_generation(self, request_id, attempts=10, delay=10):
        while attempts > 0:
            try:
                response = requests.get(self.URL + 'key/api/v1/pipeline/status/' + request_id, headers=self.AUTH_HEADERS)
                response.raise_for_status()
                data = response.json()
                if data.get('status') == 'DONE':
                    if data.get('result', {}).get('censored', False):
                        logging.warning(f"Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ {request_id} Ð±Ñ‹Ð»Ð° Ð·Ð°Ñ†ÐµÐ½Ð·ÑƒÑ€ÐµÐ½Ð°.")
                        return None, "Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð±Ñ‹Ð»Ð¾ Ð·Ð°Ñ†ÐµÐ½Ð·ÑƒÑ€ÐµÐ½Ð¾."
                    return data.get('result', {}).get('files'), None
                if data.get('status') == 'FAIL':
                    error_desc = data.get('errorDescription', 'ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ.')
                    logging.error(f"Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ {request_id} Ð¿Ñ€Ð¾Ð²Ð°Ð»ÐµÐ½Ð°: {error_desc}")
                    return None, error_desc
                attempts -= 1
                time.sleep(delay)
            except requests.RequestException as e:
                logging.error(f"HTTP Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ°: {e}")
                return None, str(e)
            except json.JSONDecodeError:
                logging.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ JSON Ð¿Ñ€Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ°: {response.text}")
                attempts -= 1
                time.sleep(delay)
        return None, "ÐŸÑ€ÐµÐ²Ñ‹ÑˆÐµÐ½Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ API."

api = FusionBrainAPI('https://api-key.fusionbrain.ai/', KANDINSKY_API_KEY, KANDINSKY_SECRET_KEY)
pipeline_id = api.get_pipeline()

async def process_image_generation(prompt):
    if not pipeline_id:
        return False, "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ID Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¾Ñ‚ API.", None
    try:
        loop = asyncio.get_event_loop()
        uuid, error = await loop.run_in_executor(None, api.generate, prompt, pipeline_id)
        if error:
            return False, f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽ: {error}", None
        files, check_error = await loop.run_in_executor(None, api.check_generation, uuid)
        if check_error:
            return False, f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸: {check_error}", None
        if not files:
            return False, "ÐÐµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (API Ð½Ðµ Ð²ÐµÑ€Ð½ÑƒÐ» Ñ„Ð°Ð¹Ð»Ñ‹)", None
        image_data_base64 = files[0]
        try:
            if ',' in image_data_base64:
                base64_data = image_data_base64.split(',')[1]
            else:
                base64_data = image_data_base64
            image_data = base64.b64decode(base64_data)
            return True, None, image_data
        except Exception as e:
            logging.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ base64: {e}")
            return False, f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ: {str(e)}", None
    except Exception as e:
        import traceback
        logging.error(f"ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð² process_image_generation: {traceback.format_exc()}")
        return False, f"ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {repr(e)[:300]}", None

# =============================================================================
# ÐšÐ°Ð»Ð°Ð¼Ð±ÑƒÑ€, ÐÐ°Ñ€Ð¸ÑÑƒÐ¹, ÐŸÐµÑ€ÐµÑ€Ð¸ÑÑƒÐ¹, ÐžÑ‚Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€ÑƒÐ¹ -> Gemini
# =============================================================================

async def handle_pun_image_command(message: types.Message):
    await bot.send_chat_action(chat_id=message.chat.id, action=random.choice(actions))
    processing_msg = await message.reply("Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ñ…ÑƒÐ¹Ð½ÑŽ...")
    pun_prompt = """ÑÐ¾ÑÑ‚Ð°Ð²ÑŒ ÐºÐ°Ð»Ð°Ð¼Ð±ÑƒÑ€Ð½Ð¾Ðµ ÑÐ¾Ñ‡ÐµÑ‚Ð°Ð½Ð¸Ðµ ÑÐ»Ð¾Ð² Ð² Ð¾Ð´Ð½Ð¾Ð¼ ÑÐ»Ð¾Ð²Ðµ. Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ð¿ÐµÑ€ÐµÑÐµÑ‡ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ†Ð° Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ ÑÐ»Ð¾Ð²Ð° Ñ Ð½Ð°Ñ‡Ð°Ð»Ð¾Ð¼ Ð²Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾. 
    Ð¡Ð¾Ð²Ð¿Ð°Ð´Ð°Ñ‚ÑŒ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ ÐºÐ°Ðº Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ Ð´Ð²Ðµ Ð±ÑƒÐºÐ²Ñ‹. 
    ÐÐµ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð¸Ñ€ÑƒÐ¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽ.
    ÐžÑ‚Ð²ÐµÑ‚ Ð´Ð°Ð¹ ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ: "ÑÐ»Ð¾Ð²Ð¾1+ÑÐ»Ð¾Ð²Ð¾2 = Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾ÐµÑÐ»Ð¾Ð²Ð¾"
    ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: "Ð¼Ð°Ð½Ð³Ð¾+Ð³Ð¾Ð»ÑƒÐ±ÑŒ = Ð¼Ð°Ð½Ð³Ð¾Ð»ÑƒÐ±ÑŒ" """
    try:
        def sync_call():
            return model.generate_content(pun_prompt).text.strip()
        pun_word = await asyncio.to_thread(sync_call)
        
        parts = pun_word.split('=')
        
        if len(parts) != 2:
            await processing_msg.edit_text(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ ÐºÐ°Ð»Ð°Ð¼Ð±ÑƒÑ€. ÐžÑ‚Ð²ÐµÑ‚ Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚Ð¸ Ð½Ðµ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ 'ÑÐ»Ð¾Ð²Ð¾1+ÑÐ»Ð¾Ð²Ð¾2 = Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾ÐµÑÐ»Ð¾Ð²Ð¾'. ÐžÑ‚Ð²ÐµÑ‚: {pun_word}")
            return

        source_words = parts[0].strip()
        final_word = parts[1].strip()

        # Ð˜Ð—ÐœÐ•ÐÐ•ÐÐ˜Ð•: ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ ÑÐ´ÐµÐ»Ð°Ð½ Ð±Ð¾Ð»ÐµÐµ Ð¿Ñ€ÑÐ¼Ñ‹Ð¼ Ð¸ "Ð¼Ð°ÑˆÐ¸Ð½Ð½Ñ‹Ð¼", Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð»Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ, Ð° Ð½Ðµ Ñ‚ÐµÐºÑÑ‚.
        image_gen_prompt = f"Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÐºÐ°Ð»Ð°Ð¼Ð±ÑƒÑ€Ð° '{final_word}'. Ð¡ÑŽÑ€Ñ€ÐµÐ°Ð»Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ð°Ñ ÐºÐ°Ñ€Ñ‚Ð¸Ð½Ð°, Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÑŽÑ‰Ð°Ñ ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ð¸ '{source_words}'. Ð‘ÐµÐ· Ð±ÑƒÐºÐ² Ð¸ Ñ‚ÐµÐºÑÑ‚Ð° Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸. Ð¤Ð¾Ñ‚Ð¾Ñ€ÐµÐ°Ð»Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ð¹ ÑÑ‚Ð¸Ð»ÑŒ."
        
        status, data = await process_gemini_generation(image_gen_prompt)

        if status == 'SUCCESS':
            image_data = data['image_data']
            # ÐÐ°ÐºÐ»Ð°Ð´Ñ‹Ð²Ð°ÐµÐ¼ Ð½Ð° Ñ‡Ð¸ÑÑ‚Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾Ðµ ÑÐ»Ð¾Ð²Ð¾
            modified_path = _overlay_text_on_image(image_data, final_word)
            await message.reply_photo(FSInputFile(modified_path))
            os.remove(modified_path)
            await processing_msg.delete()
        else:
            # Ð•ÑÐ»Ð¸ data ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ñ‚ÐµÐºÑÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð°, Ð¿Ð¾ÐºÐ°Ð¶ÐµÐ¼ ÐµÐ³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŽ
            error_text = data.get('error')
            if "Gemini Ð½Ðµ Ð²ÐµÑ€Ð½ÑƒÐ» Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ, Ð½Ð¾ Ð²ÐµÑ€Ð½ÑƒÐ» Ñ‚ÐµÐºÑÑ‚" in error_text:
                text_response = error_text.split(":", 1)[1].strip()
                await processing_msg.edit_text(f"ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ðµ ÑÐ¼Ð¾Ð³Ð»Ð° ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÑƒ, Ð½Ð¾ Ð²Ð¾Ñ‚ Ñ‡Ñ‚Ð¾ Ð¾Ð½Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ð»Ð°:\n\n_{text_response}_", parse_mode="Markdown")
            else:
                await processing_msg.edit_text(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸: {error_text}")

    except Exception as e:
        logging.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð² handle_pun_image_command: {e}", exc_info=True)
        await processing_msg.edit_text(f"ÐžÑˆÐ¸Ð±ÐºÐ°: {str(e)}")


async def handle_image_generation_command(message: types.Message):
    await bot.send_chat_action(chat_id=message.chat.id, action=random.choice(actions))
    prompt = None
    if message.text.lower().strip() == "Ð½Ð°Ñ€Ð¸ÑÑƒÐ¹" and message.reply_to_message:
        prompt = message.reply_to_message.text or message.reply_to_message.caption
    elif message.text.lower().startswith("Ð½Ð°Ñ€Ð¸ÑÑƒÐ¹ "):
        prompt = message.text[len("Ð½Ð°Ñ€Ð¸ÑÑƒÐ¹ "):].strip()
    if not prompt:
        await message.reply("Ð¨Ð¾ Ð¸Ð¼ÐµÐ½Ð½Ð¾ Ð½Ð°Ñ€Ð¸ÑÐ¾Ð²Ð°Ñ‚ÑŒ-Ñ‚Ð¾?")
        return
    processing_message = await message.reply("Ð©Ð° Ð¿Ð°Ð´Ð°Ð¶Ð¶Ð¸, Ñ€Ð¸ÑÑƒÑŽ...")
    status, data = await process_gemini_generation(prompt)
    if status == 'SUCCESS':
        await processing_message.delete()
        await save_and_send_gemini(message, data['image_data'])
    else:
        await processing_message.edit_text(f"ÐžÑˆÐ¸Ð±ÐºÐ°: {data.get('error')}")

async def handle_redraw_command(message: types.Message):
    await bot.send_chat_action(chat_id=message.chat.id, action=random.choice(actions))
    processing_msg = await message.reply("ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ñ‚Ð²Ð°ÑŽ Ð¼Ð°Ð·Ð½ÑŽ...")
    try:
        photo = None
        if message.photo:
            photo = message.photo[-1]
        elif message.document:
            photo = message.document
        elif message.reply_to_message and (message.reply_to_message.photo or message.reply_to_message.document):
            photo = message.reply_to_message.photo[-1] if message.reply_to_message.photo else message.reply_to_message.document
        if not photo:
            await processing_msg.edit_text("Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÑ€Ð¸ÑÐ¾Ð²ÐºÐ¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾.")
            return
        image_bytes = await download_telegram_image(bot, photo)
        detailed_prompt = """ÐžÐ¿Ð¸ÑˆÐ¸ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾ Ð²ÑÐµ, Ñ‡Ñ‚Ð¾ Ð²Ð¸Ð´Ð¸ÑˆÑŒ Ð½Ð° ÑÑ‚Ð¾Ð¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸. 
Ð£ÐºÐ°Ð¶Ð¸: Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð¾Ð±ÑŠÐµÐºÑ‚Ñ‹, Ñ†Ð²ÐµÑ‚Ð°, ÑÑ‚Ð¸Ð»ÑŒ, Ñ„Ð¾Ð½, Ð´ÐµÑ‚Ð°Ð»Ð¸. ÐžÐ¿Ð¸ÑˆÐ¸ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾ Ð´Ð»Ñ Ð²Ð¾ÑÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ, Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒÑÑ Ð¾Ñ‡ÐµÐ½ÑŒ Ð¿Ð»Ð¾Ñ…Ð¾ Ð¸ ÐºÑ€Ð¸Ð²Ð¾ Ð½Ð°Ñ€Ð¸ÑÐ¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ€Ð¸ÑÑƒÐ½Ð¾Ðº ÐºÐ°Ñ€Ð°Ð½Ð´Ð°ÑˆÐ¾Ð¼, ÐºÐ°Ðº Ð±ÑƒÐ´Ñ‚Ð¾ Ñ€Ð¸ÑÐ¾Ð²Ð°Ð» Ñ‚Ñ€ÐµÑ…Ð»ÐµÑ‚Ð½Ð¸Ð¹ Ñ€ÐµÐ±ÐµÐ½Ð¾Ðº. Ð’ÐµÑÑŒ Ñ‚ÐµÐºÑÑ‚ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð²Ð¼ÐµÑ‰Ð°Ñ‚ÑŒÑÑ Ð² Ð¾Ð´Ð¸Ð½ Ð°Ð±Ð·Ð°Ñ†, Ð½Ðµ Ð±Ð¾Ð»ÐµÐµ 100 ÑÐ»Ð¾Ð²"""
        def sync_describe():
            return model.generate_content([
                detailed_prompt,
                {"mime_type": "image/jpeg", "data": image_bytes}
            ]).text.strip()
        description = await asyncio.to_thread(sync_describe)
        status, data = await process_gemini_generation(description)
        if status == 'SUCCESS':
            await processing_msg.delete()
            await save_and_send_gemini(message, data['image_data'])
        else:
            await processing_msg.edit_text(f"ÐžÑˆÐ¸Ð±ÐºÐ°: {data.get('error')}")
    except Exception as e:
        logging.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð² handle_redraw_command: {e}", exc_info=True)
        await processing_msg.edit_text(f"ÐžÑˆÐ¸Ð±ÐºÐ°: {str(e)}")

# âœ¨ Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· Gemini
async def handle_edit_command(image_bytes: bytes, prompt: str):
    try:
        print("[EDIT] ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð½Ð° Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ")
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ðµ Ð¼Ð¾Ð´Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸: IMAGE + TEXT
        response = image_model.generate_content(
            [
                content_types.Image.from_bytes(image_bytes),
                prompt,
            ],
            generation_config={
                "response_modalities": ["IMAGE", "TEXT"],  # Ð²Ð°Ð¶Ð½Ð¾ ÑƒÐºÐ°Ð·Ð°Ñ‚ÑŒ IMAGE + TEXT
            }
        )

        if not response or not hasattr(response, "image"):
            raise ValueError("ÐžÑ‚Ð²ÐµÑ‚ Ð½Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ.")

        return response.image

    except Exception as e:
        print(f"[EDIT] ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: {e}")
        return None


# =============================================================================
# Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹ -> Kandinsky
# =============================================================================

async def handle_kandinsky_generation_command(message: types.Message):
    await bot.send_chat_action(chat_id=message.chat.id, action=random.choice(actions))
    prompt = None
    if message.text.lower().startswith("ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹ "):
        prompt = message.text[len("ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹ "):].strip()
    elif message.text.lower().strip() == "ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹" and message.reply_to_message:
        prompt = message.reply_to_message.text or message.reply_to_message.caption
    if not prompt:
        await message.reply("Ð§Ñ‚Ð¾ Ð¸Ð¼ÐµÐ½Ð½Ð¾ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ?")
        return
    processing_message = await message.reply("Ð”ÑƒÐ¼Ð°ÑŽ Ð½Ð°Ð´ Ð²Ð°ÑˆÐ¸Ð¼ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð¼... ðŸ¤–")
    success, error_message, image_data = await process_image_generation(prompt)
    if success and image_data:
        await processing_message.delete()
        buffered_image = types.BufferedInputFile(image_data, filename="kandinsky.png")
        await message.reply_photo(buffered_image)
    else:
        await processing_message.edit_text(f"ÐžÑˆÐ¸Ð±ÐºÐ°: {error_message}")

# =============================================================================
# Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸
# =============================================================================

def _get_text_size(font, text):
    try:
        bbox = font.getbbox(text)
        width = bbox[2] - bbox[0]
        height = bbox[3] - bbox[1]
        return width, height
    except AttributeError:
        return font.getsize(text)

def _overlay_text_on_image(image_bytes: bytes, text: str) -> str:
    image = Image.open(BytesIO(image_bytes)).convert("RGB")
    draw = ImageDraw.Draw(image)
    font_path = "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"
    if not os.path.exists(font_path):
        font_path = "arial.ttf"
    font_size = 48
    font = ImageFont.truetype(font_path, font_size)
    max_width = image.width - 40
    sample_chars = "Ð°Ð±Ð²Ð³Ð´ÐµÐ¶Ð·Ð¸Ð¹ÐºÐ»Ð¼Ð½Ð¾Ð¿Ñ€ÑÑ‚ÑƒÑ„Ñ…Ñ†Ñ‡ÑˆÑ‰ÑŠÑ‹ÑŒÑÑŽÑ"
    avg_char_width = sum(_get_text_size(font, char)[0] for char in sample_chars) / len(sample_chars)
    max_chars_per_line = int(max_width // avg_char_width) if avg_char_width > 0 else 20
    lines = textwrap.wrap(text, width=max_chars_per_line)
    _, line_height = _get_text_size(font, "A")
    text_block_height = (line_height + 5) * len(lines)
    margin_bottom = 60
    y = image.height - text_block_height - margin_bottom
    rectangle = Image.new('RGBA', (image.width, text_block_height + 40), (0, 0, 0, 128))
    image.paste(rectangle, (0, y - 20), rectangle)
    current_y = y - 10
    for line in lines:
        text_width, _ = _get_text_size(font, line)
        x = (image.width - text_width) / 2
        draw.text((x, current_y), line, font=font, fill="white", stroke_width=1, stroke_fill="black")
        current_y += line_height + 5
    output_path = "modified_pun_image.jpg"
    image.save(output_path)
    return output_path
